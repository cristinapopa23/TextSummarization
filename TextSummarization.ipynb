{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsdaRdwMNjhg",
        "outputId": "053a5823-b9a2-474c-c1d1-8b4ec7ccbd10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "metadata": {
        "id": "Y6PPG_vyNwa1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load Summarization Pipeline"
      ],
      "metadata": {
        "id": "Wp7ifFDvQn0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline('summarization')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSUNt9aIOb6V",
        "outputId": "e7179138-f133-49ee-beb6-6e62f7209a0c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Get Blog Post from Medium"
      ],
      "metadata": {
        "id": "o57DmuTVTcFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://towardsdatascience.com/a-bayesian-take-on-model-regularization-9356116b6457\""
      ],
      "metadata": {
        "id": "u2K5p18ZRb44"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = requests.get(URL)"
      ],
      "metadata": {
        "id": "k2D80YJgTUXs"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(r.text, 'html.parser')\n",
        "results = soup.find_all(['h1', 'p'])"
      ],
      "metadata": {
        "id": "kPIh8GAKUSZC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x5casqJUvPI",
        "outputId": "a3b2883e-0d48-47ad-b55f-cf38b8096114"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<p class=\"be b dw dx dy dz ea eb ec ed ee ef dt\"><span><a class=\"be b dw dx eg dy dz eh ea eb ei ec ed ej ee ef ek el em eo ep eq er es et eu ev ew ex ey ez fa bl fb\" data-testid=\"headerSignUpButton\" href=\"https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-bayesian-take-on-model-regularization-9356116b6457&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------\" rel=\"noopener follow\">Sign up</a></span></p>,\n",
              " <p class=\"be b dw dx dy dz ea eb ec ed ee ef dt\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" data-testid=\"headerSignInButton\" href=\"https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-bayesian-take-on-model-regularization-9356116b6457&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------\" rel=\"noopener follow\">Sign In</a></span></p>,\n",
              " <p class=\"be b dw dx dy dz ea eb ec ed ee ef dt\"><span><a class=\"be b dw dx eg dy dz eh ea eb ei ec ed ej ee ef ek el em eo ep eq er es et eu ev ew ex ey ez fa bl fb\" data-testid=\"headerSignUpButton\" href=\"https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-bayesian-take-on-model-regularization-9356116b6457&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------\" rel=\"noopener follow\">Sign up</a></span></p>,\n",
              " <p class=\"be b dw dx dy dz ea eb ec ed ee ef dt\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" data-testid=\"headerSignInButton\" href=\"https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-bayesian-take-on-model-regularization-9356116b6457&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------\" rel=\"noopener follow\">Sign In</a></span></p>,\n",
              " <p class=\"be b bf z dt\">Member-only story</p>,\n",
              " <h1 class=\"pw-post-title hg hh gy be hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz bj\" data-testid=\"storyTitle\" id=\"d11a\">A Bayesian Take On Model Regularization</h1>,\n",
              " <p class=\"be b jp jq bj\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar jr\" data-testid=\"authorName\" href=\"https://rmsander.medium.com/?source=post_page-----9356116b6457--------------------------------\" rel=\"noopener follow\">Ryan Sander</a></p>,\n",
              " <p class=\"be b jp jq dt\"><span><a class=\"ju jv ah ai aj ak al am an ao ap aq ar eu jw jx\" href=\"https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdca93f60cd11&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-bayesian-take-on-model-regularization-9356116b6457&amp;user=Ryan+Sander&amp;userId=dca93f60cd11&amp;source=post_page-dca93f60cd11----9356116b6457---------------------post_header-----------\" rel=\"noopener follow\">Follow</a></span></p>,\n",
              " <p class=\"be b bf z kf kg kh ki kj kk kl km bj\">Towards Data Science</p>,\n",
              " <p class=\"be b du z dt\"><span class=\"mo\">--</span></p>,\n",
              " <p class=\"be b du z dt\"><span class=\"pw-responses-count mp mq\">1</span></p>,\n",
              " <p class=\"be b bf z dt\">Share</p>,\n",
              " <p class=\"pw-post-body-paragraph ns nt gy nu b ib nv nw nx ie ny nz oa ob oc od oe of og oh oi oj ok ol om on gr bj\" id=\"8858\">I’m currently reading <em class=\"oo\">“How We Learn” </em>by Stanislas Dehaene. First off, I cannot recommend this book enough to anyone interested in learning, teaching, or AI.</p>,\n",
              " <p class=\"pw-post-body-paragraph ns nt gy nu b ib nv nw nx ie ny nz oa ob oc od oe of og oh oi oj ok ol om on gr bj\" id=\"366b\">One of the main themes of this book is explaining the <em class=\"oo\">neurological</em> and <em class=\"oo\">psychological</em> bases of why humans are so good at learning things <em class=\"oo\">quickly </em>and with great <em class=\"oo\">sample-efficiency</em>, i.e. given only a limited amount of experience¹. One of Dehaene’s main arguments of why humans can learn so effectively is because we are able to <em class=\"oo\">reduce the complexity</em> of models we formulate of the world. In accordance with the principle of <em class=\"oo\">Occam’s Razor</em>², we find the <em class=\"oo\">simplest model possible</em> that <em class=\"oo\">explains</em> the data we experience, rather than opting for more complicated models. But why do we do this, even from birth¹? One argument is that, contrary to the frequentist view in child psychology (the belief that babies learn solely through their experiences), we are already imparted with <strong class=\"nu hi\">prior</strong> beliefs about the world when we are born¹.</p>,\n",
              " <p class=\"pw-post-body-paragraph ns nt gy nu b ib nv nw nx ie ny nz oa ob oc od oe of og oh oi oj ok ol om on gr bj\" id=\"9ab5\">This notion of simplified model selection has a common name in the field of machine learning: <strong class=\"nu hi\">model regularization. </strong>In this article, we’ll talk about regularization from a <strong class=\"nu hi\">Bayesian </strong>perspective.</p>,\n",
              " <p class=\"pw-post-body-paragraph ns nt gy nu b ib nv nw nx ie ny nz oa ob oc od oe of og oh oi oj ok ol om on gr bj\" id=\"8dbf\">What’s one way we can control the <strong class=\"nu hi\">complexity </strong>of the models we learn from observations? We can do this by placing a <strong class=\"nu hi\">prior </strong>on our distribution of models. Before we show this, let’s briefly go over regularization, in this case, analytic regularization for supervised learning.</p>,\n",
              " <h1 class=\"pk pl gy be pm pn po id pp pq pr ig ps pt pu pv pw px py pz qa qb qc qd qe qf bj\" id=\"07df\">Background on Regularization</h1>,\n",
              " <p class=\"pw-post-body-paragraph ns nt gy nu b ib qg nw nx ie qh nz oa ob qi od oe of qj oh oi oj qk ol om on gr bj\" id=\"eccd\">In machine learning, <strong class=\"nu hi\">regularization</strong>, or model complexity control, is an essential and common practice to ensure that a model attains high out-of-sample performance, even if the distribution of out-of-sample data (test/validation data) differs significantly from the distribution of in-sample data (training data). In essence, the model must <em class=\"oo\">balance</em> having a small<em class=\"oo\"> empirical loss</em> (how “wrong” it is on the data it is given) with a small <em class=\"oo\">regularization loss </em>(how complicated the model is).</p>,\n",
              " <p class=\"be b du z dt\"><span class=\"mo\">--</span></p>,\n",
              " <p class=\"be b du z dt\"><span class=\"mo\">--</span></p>,\n",
              " <p class=\"be b bf z dt\"><span class=\"pw-responses-count mp mq\">1</span></p>,\n",
              " <p class=\"be b bf z kf kg kh ki kj kk kl km bj\">Towards Data Science</p>,\n",
              " <p class=\"be b bf z bj\">Image Scientist, MIT CSAIL Alum, Tutor, Dark Roast Coffee Fan, GitHub: <a class=\"af ag ah ai aj ak al am an ao ap aq ar pj gs\" href=\"https://github.com/rmsander/\" rel=\"noopener ugc nofollow\">https://github.com/rmsander/</a></p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">Ryan Sander</p>,\n",
              " <p class=\"be b du z dt\">in</p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">Towards Data Science</p>,\n",
              " <p class=\"be b du z dt\"><span class=\"mo\">--</span></p>,\n",
              " <p class=\"be b du z dt\"><span class=\"pw-responses-count mp mq\">2</span></p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">Heiko Hotz</p>,\n",
              " <p class=\"be b du z dt\">in</p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">Towards Data Science</p>,\n",
              " <p class=\"be b du z dt\"><span class=\"mo\">--</span></p>,\n",
              " <p class=\"be b du z dt\"><span class=\"pw-responses-count mp mq\">16</span></p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">Cameron R. Wolfe, Ph.D.</p>,\n",
              " <p class=\"be b du z dt\">in</p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">Towards Data Science</p>,\n",
              " <p class=\"be b du z dt\"><span class=\"mo\">--</span></p>,\n",
              " <p class=\"be b du z dt\"><span class=\"pw-responses-count mp mq\">8</span></p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">Ryan Sander</p>,\n",
              " <p class=\"be b du z dt\">in</p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">Towards Data Science</p>,\n",
              " <p class=\"be b du z dt\"><span class=\"mo\">--</span></p>,\n",
              " <p class=\"be b du z dt\"><span class=\"pw-responses-count mp mq\">3</span></p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">Piero Paialunga</p>,\n",
              " <p class=\"be b du z dt\">in</p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">Towards Data Science</p>,\n",
              " <p class=\"be b du z dt\"><span class=\"mo\">--</span></p>,\n",
              " <p class=\"be b du z dt\"><span class=\"pw-responses-count mp mq\">11</span></p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">Théo Martin</p>,\n",
              " <p class=\"be b du z dt\"><span class=\"mo\">--</span></p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">PyMC Labs</p>,\n",
              " <p class=\"be b du z dt\"><span class=\"mo\">--</span></p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">Maximilian Vogel</p>,\n",
              " <p class=\"be b du z dt\">in</p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">MLearning.ai</p>,\n",
              " <p class=\"be b du z dt\"><span class=\"mo\">--</span></p>,\n",
              " <p class=\"be b du z dt\"><span class=\"pw-responses-count mp mq\">105</span></p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">VN040424</p>,\n",
              " <p class=\"be b du z dt\"><span class=\"mo\">--</span></p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">Ido Finder</p>,\n",
              " <p class=\"be b du z dt\">in</p>,\n",
              " <p class=\"be b du z kf kg kh ki kj kk kl km bj\">AppsFlyer Engineering</p>,\n",
              " <p class=\"be b du z dt\"><span class=\"mo\">--</span></p>,\n",
              " <p class=\"be b du z dt\"><span class=\"pw-responses-count mp mq\">3</span></p>,\n",
              " <p class=\"be b du z dt\">Help</p>,\n",
              " <p class=\"be b du z dt\">Status</p>,\n",
              " <p class=\"be b du z dt\">Writers</p>,\n",
              " <p class=\"be b du z dt\">Blog</p>,\n",
              " <p class=\"be b du z dt\">Careers</p>,\n",
              " <p class=\"be b du z dt\">Privacy</p>,\n",
              " <p class=\"be b du z dt\">Terms</p>,\n",
              " <p class=\"be b du z dt\">About</p>,\n",
              " <p class=\"be b du z dt\">Text to speech</p>,\n",
              " <p class=\"be b du z dt\">Teams</p>]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [result.text for result in results]\n",
        "ARTICLE = ' '.join(text)"
      ],
      "metadata": {
        "id": "0LitIjn3WVkg"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ARTICLE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "oiNBR9qna258",
        "outputId": "e2430124-5431-4379-9c6e-6840be18ebfc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sign up Sign In Sign up Sign In Member-only story A Bayesian Take On Model Regularization Ryan Sander Follow Towards Data Science -- 1 Share I’m currently reading “How We Learn” by Stanislas Dehaene. First off, I cannot recommend this book enough to anyone interested in learning, teaching, or AI. One of the main themes of this book is explaining the neurological and psychological bases of why humans are so good at learning things quickly and with great sample-efficiency, i.e. given only a limited amount of experience¹. One of Dehaene’s main arguments of why humans can learn so effectively is because we are able to reduce the complexity of models we formulate of the world. In accordance with the principle of Occam’s Razor², we find the simplest model possible that explains the data we experience, rather than opting for more complicated models. But why do we do this, even from birth¹? One argument is that, contrary to the frequentist view in child psychology (the belief that babies learn solely through their experiences), we are already imparted with prior beliefs about the world when we are born¹. This notion of simplified model selection has a common name in the field of machine learning: model regularization. In this article, we’ll talk about regularization from a Bayesian perspective. What’s one way we can control the complexity of the models we learn from observations? We can do this by placing a prior on our distribution of models. Before we show this, let’s briefly go over regularization, in this case, analytic regularization for supervised learning. Background on Regularization In machine learning, regularization, or model complexity control, is an essential and common practice to ensure that a model attains high out-of-sample performance, even if the distribution of out-of-sample data (test/validation data) differs significantly from the distribution of in-sample data (training data). In essence, the model must balance having a small empirical loss (how “wrong” it is on the data it is given) with a small regularization loss (how complicated the model is). -- -- 1 Towards Data Science Image Scientist, MIT CSAIL Alum, Tutor, Dark Roast Coffee Fan, GitHub: https://github.com/rmsander/ Ryan Sander in Towards Data Science -- 2 Heiko Hotz in Towards Data Science -- 16 Cameron R. Wolfe, Ph.D. in Towards Data Science -- 8 Ryan Sander in Towards Data Science -- 3 Piero Paialunga in Towards Data Science -- 11 Théo Martin -- PyMC Labs -- Maximilian Vogel in MLearning.ai -- 105 VN040424 -- Ido Finder in AppsFlyer Engineering -- 3 Help Status Writers Blog Careers Privacy Terms About Text to speech Teams'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Chunk Text"
      ],
      "metadata": {
        "id": "CrJ1X5LsbwzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ARTICLE = ARTICLE.replace('.','.<eos>') # end-of-sentence tag\n",
        "ARTICLE = ARTICLE.replace('!','!<eos>')\n",
        "ARTICLE = ARTICLE.replace('?','?<eos>')\n",
        "sentences = ARTICLE.split('<eos>')"
      ],
      "metadata": {
        "id": "m5kO834xbynD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny6d7bkmOCbk",
        "outputId": "0ff6aec2-03b8-412d-aa70-c79736a67dca"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sign up Sign In Sign up Sign In Member-only story A Bayesian Take On Model Regularization Ryan Sander Follow Towards Data Science -- 1 Share I’m currently reading “How We Learn” by Stanislas Dehaene.',\n",
              " ' First off, I cannot recommend this book enough to anyone interested in learning, teaching, or AI.',\n",
              " ' One of the main themes of this book is explaining the neurological and psychological bases of why humans are so good at learning things quickly and with great sample-efficiency, i.',\n",
              " 'e.',\n",
              " ' given only a limited amount of experience¹.',\n",
              " ' One of Dehaene’s main arguments of why humans can learn so effectively is because we are able to reduce the complexity of models we formulate of the world.',\n",
              " ' In accordance with the principle of Occam’s Razor², we find the simplest model possible that explains the data we experience, rather than opting for more complicated models.',\n",
              " ' But why do we do this, even from birth¹?',\n",
              " ' One argument is that, contrary to the frequentist view in child psychology (the belief that babies learn solely through their experiences), we are already imparted with prior beliefs about the world when we are born¹.',\n",
              " ' This notion of simplified model selection has a common name in the field of machine learning: model regularization.',\n",
              " ' In this article, we’ll talk about regularization from a Bayesian perspective.',\n",
              " ' What’s one way we can control the complexity of the models we learn from observations?',\n",
              " ' We can do this by placing a prior on our distribution of models.',\n",
              " ' Before we show this, let’s briefly go over regularization, in this case, analytic regularization for supervised learning.',\n",
              " ' Background on Regularization In machine learning, regularization, or model complexity control, is an essential and common practice to ensure that a model attains high out-of-sample performance, even if the distribution of out-of-sample data (test/validation data) differs significantly from the distribution of in-sample data (training data).',\n",
              " ' In essence, the model must balance having a small empirical loss (how “wrong” it is on the data it is given) with a small regularization loss (how complicated the model is).',\n",
              " ' -- -- 1 Towards Data Science Image Scientist, MIT CSAIL Alum, Tutor, Dark Roast Coffee Fan, GitHub: https://github.',\n",
              " 'com/rmsander/ Ryan Sander in Towards Data Science -- 2 Heiko Hotz in Towards Data Science -- 16 Cameron R.',\n",
              " ' Wolfe, Ph.',\n",
              " 'D.',\n",
              " ' in Towards Data Science -- 8 Ryan Sander in Towards Data Science -- 3 Piero Paialunga in Towards Data Science -- 11 Théo Martin -- PyMC Labs -- Maximilian Vogel in MLearning.',\n",
              " 'ai -- 105 VN040424 -- Ido Finder in AppsFlyer Engineering -- 3 Help Status Writers Blog Careers Privacy Terms About Text to speech Teams']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_chunk = 500\n",
        "current_chunk = 0\n",
        "chunks = []\n",
        "\n",
        "for sentence in sentences:\n",
        "  if len(chunks) == current_chunk + 1:\n",
        "    if len(chunks[current_chunk]) + len(sentence.split(' ')) <= max_chunk:\n",
        "      chunks[current_chunk].extend(sentence.split(' '))\n",
        "    else:\n",
        "      current_chunk += 1\n",
        "      chunks.append(sentence.split(' '))\n",
        "  else:\n",
        "    print(current_chunk)\n",
        "    chunks.append(sentence.split(' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ8trs5-QG1d",
        "outputId": "e1ef7443-e422-4d7e-96db-bd74f8de44da"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk_id in range(len(chunks)):\n",
        "  chunks[chunk_id]=' '.join(chunks[chunk_id])"
      ],
      "metadata": {
        "id": "7LJvqjRxZDVS"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Summarize Text"
      ],
      "metadata": {
        "id": "pJ87RqJabHFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = summarizer(chunks, max_length=120, min_length=30, do_sample=False)"
      ],
      "metadata": {
        "id": "vpmBoI-YbKfe"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtzawXQobbLP",
        "outputId": "065974d1-36e9-4b6d-f880-acc848b8540f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' A Bayesian take on model regularization from a Bayesian perspective . In machine learning, regularization, or model complexity control, is an essential practice to ensure that a model attains high out-of-sample performance . We can do this by placing a prior on our distribution of models .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join([summ['summary_text'] for summ in res])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "fm75dvpmdPMk",
        "outputId": "930498fc-da8f-4000-9f26-e9c9c74e48b8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' A Bayesian take on model regularization from a Bayesian perspective . In machine learning, regularization, or model complexity control, is an essential practice to ensure that a model attains high out-of-sample performance . We can do this by placing a prior on our distribution of models .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Output Text File"
      ],
      "metadata": {
        "id": "4cw8k1RWd9Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join([summ['summary_text'] for summ in res])"
      ],
      "metadata": {
        "id": "oXelNKe6eQAq"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('blogsummary.txt','w') as f:\n",
        "  f.write(text)"
      ],
      "metadata": {
        "id": "vOBoQaGGeYHH"
      },
      "execution_count": 64,
      "outputs": []
    }
  ]
}